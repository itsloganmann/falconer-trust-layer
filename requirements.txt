# Falconer Trust Layer - Mechanistic Interpretability Dependencies
# For Google Colab H100 (80GB VRAM)

# Core ML framework
torch>=2.1.0

# TransformerLens for mechanistic interpretability
transformer_lens>=1.15.0

# Tensor operations
einops>=0.7.0

# Type annotations for tensors
jaxtyping>=0.2.25

# Accelerated model loading
accelerate>=0.25.0

# Terminal output formatting
colorama>=0.4.6

# Numerical computing
numpy>=1.24.0

# Hugging Face integration (required by transformer_lens)
transformers>=4.36.0
tokenizers>=0.15.0

# Optional: For Llama models (may require authentication)
# huggingface_hub>=0.19.0
